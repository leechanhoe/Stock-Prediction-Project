{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5Nv0eK6QVyW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh9d8l_PQ89m",
        "outputId": "434f8ddc-a253-482c-a7e9-ad5b3d12d8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_images = np.load('drive/MyDrive/Colab Notebooks/train_images_kosdaq_change10_2.npy')\n",
        "# train_labels = np.load('drive/MyDrive/Colab Notebooks/train_labels_kosdaq_change10_2.npy')\n",
        "test_images = np.load('drive/MyDrive/Colab Notebooks/test_images_kosdaq.npy')\n",
        "test_labels = np.load('drive/MyDrive/Colab Notebooks/test_labels_kosdaq.npy')"
      ],
      "metadata": {
        "id": "51uF5k_dQbbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F9HMIWQDoK_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_images = np.array(train_images).reshape(-1, 96, 96, 3) / 255.0\n",
        "test_images = np.array(test_images).reshape(-1, 96, 96, 3) / 255.0\n",
        "\n",
        "# train_images, test_images, train_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.2)\n",
        "\n",
        "# train_labels_one_hot = np.eye(2)[train_labels]\n",
        "test_labels_one_hot = np.eye(2)[test_labels]"
      ],
      "metadata": {
        "id": "WYFCbpYqR35_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Convolutional Block (Conv-Conv-Pool-Dropout)\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(96, 96, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Convolutional Block (Conv-Conv-Pool-Dropout)\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten()) # change this line\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "hHxW7kAYR9td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 3:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 5:\n",
        "        lrate = 0.0001\n",
        "    if epoch > 10:\n",
        "        lrate = 0.00005\n",
        "\n",
        "    return lrate\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('best_cnn_model.h5', save_best_only=True, monitor='val_acc')\n",
        "# N번의 연속적인 epoch 동안 개선이 없을 때 학습이 중단되도록 함\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=30, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "0C6hjJC8Si0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "history = model.fit(train_images, train_labels_one_hot, batch_size=32, epochs=100, validation_data=(test_images, test_labels_one_hot),\n",
        "                    callbacks=[checkpoint, early_stopping, LearningRateScheduler(lr_schedule)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhFl-WnxSWFA",
        "outputId": "33a7446b-1a26-4959-edc8-6c9fb63eec1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "313/313 [==============================] - 43s 91ms/step - loss: 2.3674 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4980 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "313/313 [==============================] - 31s 98ms/step - loss: 0.6910 - acc: 0.5219 - val_loss: 0.6938 - val_acc: 0.5115 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.6903 - acc: 0.5243 - val_loss: 0.6942 - val_acc: 0.4905 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6910 - acc: 0.5241 - val_loss: 0.6919 - val_acc: 0.5030 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6888 - acc: 0.5226 - val_loss: 0.6950 - val_acc: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6871 - acc: 0.5263 - val_loss: 0.6927 - val_acc: 0.4985 - lr: 5.0000e-04\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6867 - acc: 0.5204 - val_loss: 0.6944 - val_acc: 0.5060 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6801 - acc: 0.5416 - val_loss: 0.6941 - val_acc: 0.5045 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6759 - acc: 0.5629 - val_loss: 0.6955 - val_acc: 0.5060 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6766 - acc: 0.5591 - val_loss: 0.6966 - val_acc: 0.5020 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 31s 99ms/step - loss: 0.6715 - acc: 0.5700 - val_loss: 0.6959 - val_acc: 0.5230 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 27s 87ms/step - loss: 0.6668 - acc: 0.5771 - val_loss: 0.6954 - val_acc: 0.5000 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6670 - acc: 0.5799 - val_loss: 0.6981 - val_acc: 0.4965 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6656 - acc: 0.5755 - val_loss: 0.6966 - val_acc: 0.5160 - lr: 5.0000e-05\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6631 - acc: 0.5790 - val_loss: 0.7021 - val_acc: 0.5035 - lr: 5.0000e-05\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6657 - acc: 0.5808 - val_loss: 0.6990 - val_acc: 0.5155 - lr: 5.0000e-05\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6614 - acc: 0.5831 - val_loss: 0.7013 - val_acc: 0.5190 - lr: 5.0000e-05\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6589 - acc: 0.5919 - val_loss: 0.6975 - val_acc: 0.5125 - lr: 5.0000e-05\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6560 - acc: 0.5908 - val_loss: 0.6976 - val_acc: 0.5190 - lr: 5.0000e-05\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 25s 81ms/step - loss: 0.6519 - acc: 0.5992 - val_loss: 0.7028 - val_acc: 0.5115 - lr: 5.0000e-05\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 0.6522 - acc: 0.5954 - val_loss: 0.7047 - val_acc: 0.5280 - lr: 5.0000e-05\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.6488 - acc: 0.6022 - val_loss: 0.7049 - val_acc: 0.5285 - lr: 5.0000e-05\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6415 - acc: 0.6051 - val_loss: 0.7005 - val_acc: 0.5245 - lr: 5.0000e-05\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6383 - acc: 0.6131 - val_loss: 0.7063 - val_acc: 0.5150 - lr: 5.0000e-05\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 29s 92ms/step - loss: 0.6333 - acc: 0.6161 - val_loss: 0.7132 - val_acc: 0.5310 - lr: 5.0000e-05\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.6299 - acc: 0.6203 - val_loss: 0.7059 - val_acc: 0.5265 - lr: 5.0000e-05\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 31s 99ms/step - loss: 0.6236 - acc: 0.6207 - val_loss: 0.7066 - val_acc: 0.5325 - lr: 5.0000e-05\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.6158 - acc: 0.6326 - val_loss: 0.7198 - val_acc: 0.5315 - lr: 5.0000e-05\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.6124 - acc: 0.6342 - val_loss: 0.7141 - val_acc: 0.5245 - lr: 5.0000e-05\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.6110 - acc: 0.6331 - val_loss: 0.7061 - val_acc: 0.5245 - lr: 5.0000e-05\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.6017 - acc: 0.6457 - val_loss: 0.7169 - val_acc: 0.5300 - lr: 5.0000e-05\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.5948 - acc: 0.6474 - val_loss: 0.7118 - val_acc: 0.5255 - lr: 5.0000e-05\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 27s 87ms/step - loss: 0.5881 - acc: 0.6446 - val_loss: 0.7270 - val_acc: 0.5340 - lr: 5.0000e-05\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5813 - acc: 0.6539 - val_loss: 0.7412 - val_acc: 0.5335 - lr: 5.0000e-05\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5760 - acc: 0.6587 - val_loss: 0.7402 - val_acc: 0.5235 - lr: 5.0000e-05\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5653 - acc: 0.6715 - val_loss: 0.7301 - val_acc: 0.5325 - lr: 5.0000e-05\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 31s 100ms/step - loss: 0.5634 - acc: 0.6711 - val_loss: 0.7512 - val_acc: 0.5360 - lr: 5.0000e-05\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5544 - acc: 0.6763 - val_loss: 0.7337 - val_acc: 0.5295 - lr: 5.0000e-05\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.5419 - acc: 0.6792 - val_loss: 0.7598 - val_acc: 0.5300 - lr: 5.0000e-05\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 27s 87ms/step - loss: 0.5408 - acc: 0.6881 - val_loss: 0.7418 - val_acc: 0.5425 - lr: 5.0000e-05\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5252 - acc: 0.6991 - val_loss: 0.7549 - val_acc: 0.5240 - lr: 5.0000e-05\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5176 - acc: 0.7061 - val_loss: 0.7499 - val_acc: 0.5400 - lr: 5.0000e-05\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.5144 - acc: 0.7083 - val_loss: 0.7662 - val_acc: 0.5415 - lr: 5.0000e-05\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4979 - acc: 0.7162 - val_loss: 0.7587 - val_acc: 0.5355 - lr: 5.0000e-05\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4898 - acc: 0.7203 - val_loss: 0.8004 - val_acc: 0.5305 - lr: 5.0000e-05\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4822 - acc: 0.7251 - val_loss: 0.7734 - val_acc: 0.5350 - lr: 5.0000e-05\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4655 - acc: 0.7378 - val_loss: 0.8251 - val_acc: 0.5250 - lr: 5.0000e-05\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.4599 - acc: 0.7359 - val_loss: 0.7975 - val_acc: 0.5300 - lr: 5.0000e-05\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4469 - acc: 0.7490 - val_loss: 0.8161 - val_acc: 0.5210 - lr: 5.0000e-05\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.4450 - acc: 0.7508 - val_loss: 0.8314 - val_acc: 0.5285 - lr: 5.0000e-05\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4274 - acc: 0.7591 - val_loss: 0.8296 - val_acc: 0.5300 - lr: 5.0000e-05\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.4195 - acc: 0.7682 - val_loss: 0.8367 - val_acc: 0.5220 - lr: 5.0000e-05\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4131 - acc: 0.7700 - val_loss: 0.8460 - val_acc: 0.5305 - lr: 5.0000e-05\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4104 - acc: 0.7717 - val_loss: 0.8684 - val_acc: 0.5180 - lr: 5.0000e-05\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.4027 - acc: 0.7762 - val_loss: 0.8999 - val_acc: 0.5155 - lr: 5.0000e-05\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3825 - acc: 0.7896 - val_loss: 0.9504 - val_acc: 0.5130 - lr: 5.0000e-05\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3794 - acc: 0.7922 - val_loss: 0.9102 - val_acc: 0.5195 - lr: 5.0000e-05\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3649 - acc: 0.8017 - val_loss: 0.9722 - val_acc: 0.5175 - lr: 5.0000e-05\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.3546 - acc: 0.8092 - val_loss: 0.9645 - val_acc: 0.5250 - lr: 5.0000e-05\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.3498 - acc: 0.8067 - val_loss: 0.9492 - val_acc: 0.5270 - lr: 5.0000e-05\n",
            "Epoch 61/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3408 - acc: 0.8160 - val_loss: 0.9877 - val_acc: 0.5200 - lr: 5.0000e-05\n",
            "Epoch 62/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.3333 - acc: 0.8163 - val_loss: 0.9966 - val_acc: 0.5215 - lr: 5.0000e-05\n",
            "Epoch 63/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3246 - acc: 0.8268 - val_loss: 1.0325 - val_acc: 0.5025 - lr: 5.0000e-05\n",
            "Epoch 64/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.3276 - acc: 0.8226 - val_loss: 1.0117 - val_acc: 0.5190 - lr: 5.0000e-05\n",
            "Epoch 65/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.3086 - acc: 0.8348 - val_loss: 1.0783 - val_acc: 0.5260 - lr: 5.0000e-05\n",
            "Epoch 66/100\n",
            "313/313 [==============================] - 26s 83ms/step - loss: 0.3060 - acc: 0.8375 - val_loss: 1.0412 - val_acc: 0.5175 - lr: 5.0000e-05\n",
            "Epoch 67/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.2932 - acc: 0.8413 - val_loss: 1.0618 - val_acc: 0.5215 - lr: 5.0000e-05\n",
            "Epoch 68/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.2928 - acc: 0.8461 - val_loss: 1.0511 - val_acc: 0.5235 - lr: 5.0000e-05\n",
            "Epoch 69/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.2873 - acc: 0.8461 - val_loss: 1.0679 - val_acc: 0.5170 - lr: 5.0000e-05\n",
            "Epoch 70/100\n",
            "313/313 [==============================] - 26s 82ms/step - loss: 0.2770 - acc: 0.8532 - val_loss: 1.1237 - val_acc: 0.5185 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model40 = load_model('drive/MyDrive/Colab Notebooks/kosdaq_epoch40.h5')\n",
        "model75 = load_model('drive/MyDrive/Colab Notebooks/kosdaq_epoch75.h5')"
      ],
      "metadata": {
        "id": "wwUkDW0cS3RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model40.evaluate(test_images, test_labels_one_hot, verbose=2)\n",
        "test_loss, test_acc = model75.evaluate(test_images, test_labels_one_hot, verbose=2)"
      ],
      "metadata": {
        "id": "MDHzRodjlwEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de22b848-0555-4f58-aae1-e72d1307493f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 8s - loss: 0.7729 - acc: 0.5024 - 8s/epoch - 27ms/step\n",
            "313/313 - 6s - loss: 1.1009 - acc: 0.5052 - 6s/epoch - 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터셋에 대한 예측 생성\n",
        "pred_probs40 = model40.predict(test_images)\n",
        "pred_probs75 = model75.predict(test_images)"
      ],
      "metadata": {
        "id": "AyZd6wFJfADB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0bf5c0-920e-4c05-dd56-f9d5203d6669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 16ms/step\n",
            "313/313 [==============================] - 5s 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 모델만 실험\n",
        "\n",
        "selected_images = []\n",
        "selected_labels = []\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    if 0.5 < pred_probs40[i][0] and any(0.792 <= p < 0.82 for p in pred_probs40[i]):\n",
        "        selected_images.append(test_images[i])\n",
        "        selected_labels.append(test_labels_one_hot[i])\n",
        "\n",
        "selected_images = np.array(selected_images)\n",
        "selected_labels = np.array(selected_labels)\n",
        "\n",
        "print(len(selected_images))\n",
        "print(sum(selected_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR-cfmfLNkSy",
        "outputId": "f2c5e01d-6e29-418f-94ca-9d3bbdbe3e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111\n",
            "[67. 44.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 모델 같은 라벨이 정답이라고 했을때\n",
        "\n",
        "selected_images = []\n",
        "selected_labels = []\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    pred_probs75_max_idx = np.argmax(pred_probs75[i])\n",
        "    pred_probs40_max_idx = np.argmax(pred_probs40[i])\n",
        "\n",
        "    if pred_probs75_max_idx == pred_probs40_max_idx and pred_probs75_max_idx == 1 and 0.999 <= pred_probs75[i][pred_probs75_max_idx] <= 0.9999 and 0.83 <= pred_probs40[i][pred_probs40_max_idx] <= 0.95:\n",
        "        selected_images.append(test_images[i])\n",
        "        selected_labels.append(test_labels_one_hot[i])\n",
        "\n",
        "selected_images = np.array(selected_images)\n",
        "selected_labels = np.array(selected_labels)\n",
        "\n",
        "print(len(selected_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8agM4JhrtgI",
        "outputId": "76db68a7-f99c-46d2-d564-9ef59d97df93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 모델 같은 라벨이 정답이라고 했을때\n",
        "\n",
        "selected_images = []\n",
        "selected_labels = []\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    pred_probs75_max_idx = np.argmax(pred_probs75[i])\n",
        "    pred_probs40_max_idx = np.argmax(pred_probs40[i])\n",
        "\n",
        "    if pred_probs75_max_idx == pred_probs40_max_idx and pred_probs75_max_idx == 0 and 0.97 <= pred_probs75[i][pred_probs75_max_idx] <= 0.99 and 0.79 <= pred_probs40[i][pred_probs40_max_idx] <= 0.86:\n",
        "        selected_images.append(test_images[i])\n",
        "        selected_labels.append(test_labels_one_hot[i])\n",
        "\n",
        "selected_images = np.array(selected_images)\n",
        "selected_labels = np.array(selected_labels)\n",
        "\n",
        "print(len(selected_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYztO94lt2In",
        "outputId": "fc774805-cc3b-4743-e89e-3ea96deba663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model75.evaluate(selected_images, selected_labels, verbose=2)\n",
        "test_loss, test_acc = model40.evaluate(selected_images, selected_labels, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY07Jgl4Nxcs",
        "outputId": "5b3a63f3-210f-4366-85f3-75495f50344c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 2.7510 - acc: 0.6538 - 46ms/epoch - 46ms/step\n",
            "1/1 - 0s - loss: 0.8619 - acc: 0.6538 - 41ms/epoch - 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 검증 데이터에 대한 예측 값 얻기\n",
        "y_pred = model.predict(selected_images)\n",
        "\n",
        "# 예측 결과를 이진 형태로 변환 (임계값을 0.5로 설정)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)[:, 0]\n",
        "test_labels_indices = selected_labels.astype(int)[:, 0]\n",
        "\n",
        "# Confusion matrix 얻기\n",
        "tn, fp, fn, tp = confusion_matrix(test_labels_indices, y_pred_classes).ravel()\n",
        "\n",
        "# 정밀도\n",
        "precision = tp / (tp + fp)\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "negative_predictive_alue = tn / (tn + fn)\n",
        "print(\"진음성 : \", negative_predictive_alue)\n",
        "\n",
        "# 재현율 (Recall, Sensitivity, True Positive Rate, TPR) 계산\n",
        "recall = tp / (tp + fn)\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "# 특이도 (Specificity, True Negative Rate, TNR) 계산\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity: \", specificity)\n",
        "\n",
        "# 위양성율 (False Positive Rate, FPR) 계산\n",
        "false_positive_rate = fp / (fp + tn)\n",
        "print(\"False Positive Rate: \", false_positive_rate)\n",
        "\n",
        "# 위음성율 (False Negative Rate, FNR) 계산\n",
        "false_negative_rate = fn / (fn + tp)\n",
        "print(\"False Negative Rate: \", false_negative_rate)\n",
        "\n",
        "f1 = 2 * precision * recall / (precision + recall)\n",
        "print(\"F1-score : \", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUJVIKJFEP31",
        "outputId": "2717301b-d98f-49a9-844a-497befe1cdac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 12s 16ms/step\n",
            "Precision:  0.5050702028081123\n",
            "진음성 :  0.5053366174055829\n",
            "Recall:  0.518\n",
            "Specificity:  0.4924\n",
            "False Positive Rate:  0.5076\n",
            "False Negative Rate:  0.482\n",
            "F1-score :  0.5114533965244866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlsI6CmlXfmL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}